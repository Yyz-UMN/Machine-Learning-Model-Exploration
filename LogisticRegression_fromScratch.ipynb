{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create logistic regression model with batch gradient descent solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up sigmoid link function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$g(z) = \\frac{1}{1 + exp(-z)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h_\\beta(x) = g(\\beta^T x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set all default weights to 1 (including bias term w)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(weights,features):\n",
    "    z = np.dot(weights,features.T)\n",
    "    hypo = 1.0/(1+np.exp(-z))\n",
    "    return hypo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up classifier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cl(hypo):\n",
    "    predictions=hypo-(1-hypo)\n",
    "    predictions[predictions>=0] = 1\n",
    "    predictions[predictions<0] = 0\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up log-loss cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$J(\\beta ) = -\\frac{1}{m} \\sum_{i=1}^m[y_i log(h_\\beta (x_i) + (1 â€“ y_i) log(1-h_\\beta (x_i))]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(targets,scores):\n",
    "    m = len(targets)\n",
    "    lloss = -(np.dot(targets,np.log(scores.T))+np.dot((1-targets),np.log(1-scores.T)))/m\n",
    "    return lloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grd(predictions,features,targets,alpha,weights):\n",
    "    m = features.shape[1]\n",
    "    grd=np.dot((predictions-targets),features)\n",
    "    weights_updated=weights-np.dot(alpha,grd)\n",
    "    return weights_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build logistic regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(features,targets, tol=0.0001, max_iter=100):\n",
    "    # reshape targets\n",
    "    targets = targets.reshape(1,-1)\n",
    "    \n",
    "    # augment feature vector to accomdate bias term in the model\n",
    "    features = np.hstack((features,np.ones((features.shape[0],1))))\n",
    "    \n",
    "    # initialize weights\n",
    "    weights = np.matrix(np.ones((1,features.shape[1])))\n",
    "    \n",
    "    # compute initial scores (hypothesis out)\n",
    "    scores = sigmoid(weights,features)\n",
    "    \n",
    "    # compute initial predictions\n",
    "    predictions = cl(scores)\n",
    "    \n",
    "    # compute initial logloss\n",
    "    cost = logloss(targets,scores)\n",
    "    \n",
    "    # use batch gradient descent to estimate model coefficients\n",
    "    n_iterations = max_iter\n",
    "    learning_rate = 0.001 # set default learning rate to 0.001\n",
    "    cost_delta = tol\n",
    "    \n",
    "    while n_iterations>0 and cost_delta>=tol: # set up stopping criteria\n",
    "        weights_updated = grd(predictions,features,targets,learning_rate,weights)\n",
    "        scores = sigmoid(weights_updated,features)\n",
    "        predictions = cl(scores)\n",
    "        cost_updated = logloss(targets,scores)\n",
    "        cost_delta = cost - cost_updated\n",
    "        \n",
    "        cost = cost_updated\n",
    "        n_iterations-=1\n",
    "        \n",
    "        if cost_delta > 0:\n",
    "            weights = weights_updated\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return weights,predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model and solver on Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load preprocessed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = pd.read_csv('../Data/train_X.csv')\n",
    "train_y = pd.read_csv('../Data/train_y.csv',squeeze=True)\n",
    "test_X = pd.read_csv('../Data/test_X.csv')\n",
    "test_y = pd.read_csv('../Data/test_y.csv',squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = np.matrix(train_X)\n",
    "train_y = np.array(train_y)\n",
    "test_X = np.matrix(test_X)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit hand-made LR model on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,predictions = logistic_regression(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.07579007, -0.09043556, -0.13758667, -0.04715164,  0.49496346,\n",
       "         -0.273     ,  0.541     ,  0.247     , -0.01      ]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7223113964686998"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_y, predictions.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_aug = np.hstack((test_X,np.ones((test_X.shape[0],1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = sigmoid(w,test_X_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = cl(test_scores).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73134328358208955"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_predictions,test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit sklearn LR model on data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_sklearn = lr(C=1e15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1e+15, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_sklearn.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.853682  , -0.57435996, -0.34506289, -0.03165663,  0.10383695,\n",
       "        -2.82151961, -0.19328792, -0.32573504]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_sklearn.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.41905563])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_sklearn.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8025682182985554"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_sklearn.score(train_X,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79104477611940294"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_sklearn.score(test_X,test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
